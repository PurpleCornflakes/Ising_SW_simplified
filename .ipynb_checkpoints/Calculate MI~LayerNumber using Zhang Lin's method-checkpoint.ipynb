{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Mutual information estimator from\n",
    "- `\"Understanding autoencoders with...\" <https://arxiv.org/pdf/1804.00057.pdf>`_ paper\n",
    "- `\"Understanding Convolutional num_sampleseural num_samplesetworks with...\"\n",
    "    <https://arxiv.org/pdf/1804.06537.pdf>`_ paper.\n",
    "\n",
    "Based on the implementation in the above two papers:\n",
    "- https://drive.google.com/drive/folders/1e5sIywZfmWp4Dn0WEesb6fqQRM0DIGxZ\n",
    "- https://drive.google.com/drive/folders/1SlxzEOX8RbnLwCgRyqGwMOL7vuT90Gje\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def guassian_matrix(X, sigma):\n",
    "    '''Apply a guassian kernel on a realization X.\n",
    "\n",
    "    Args:\n",
    "        X: a realization of a layer activation distribution.\n",
    "        sigma: parameter of the guassian kernel.\n",
    "\n",
    "    Returns:\n",
    "        Gram matrix K.\n",
    "    '''\n",
    "    G = np.matmul(X, X.T)\n",
    "    K = np.exp(-(1/(2*sigma**2)) * (np.diag(G)[:, np.newaxis]\n",
    "                                    + np.diag(G)[np.newaxis, :] - 2*G))\n",
    "\n",
    "    return K\n",
    "\n",
    "def silvermanmi_univariate(inputdata, layerdata, alpha):\n",
    "    '''Calculate mutual information.\n",
    "\n",
    "    Args:\n",
    "        inputdata: Activations of input with dimension\n",
    "            (args.num_samples, input dimension).\n",
    "        layerdata: Activations of a hidden layer with dimension\n",
    "            (args.num_samples, layer dimension).\n",
    "        alpha: alpha in the definition of matrix based renyi entropy.\n",
    "\n",
    "    Returns:\n",
    "        mutual information\n",
    "    '''\n",
    "    num_samples = inputdata.shape[0]\n",
    "    sigma1 = 6 * np.power(num_samples, -1/(4 + inputdata.shape[1]))\n",
    "    sigma2 = 6 * np.power(num_samples, -1/(4 + layerdata.shape[1]))\n",
    "    print(sigma1, sigma2)\n",
    "    # Estimate entropy\n",
    "    K_x = np.real(guassian_matrix(inputdata, sigma1)) / num_samples\n",
    "    L_x, _ = np.linalg.eig(K_x)\n",
    "    lambda_x = np.absolute(L_x)\n",
    "    H_x = (1 / (1-alpha)) * np.log((np.sum(np.power(lambda_x, alpha))))\n",
    "\n",
    "    K_t = np.real(guassian_matrix(layerdata, sigma2)) / num_samples\n",
    "    L_t, _ = np.linalg.eig(K_t)\n",
    "    lambda_t = np.absolute(L_t)\n",
    "    H_t = (1 / (1-alpha)) * np.log((np.sum(np.power(lambda_t, alpha))))\n",
    "\n",
    "    # Estimate joint entropy\n",
    "    K_xt = np.multiply(K_x, K_t) * num_samples\n",
    "    L_xt, _ = np.linalg.eig(K_xt)\n",
    "    lambda_xt = np.absolute(L_xt)\n",
    "    H_xt = (1 / (1-alpha)) * np.log(np.sum(np.power(lambda_xt, alpha)))\n",
    "\n",
    "    # Estimate mutual information\n",
    "    mutual_information = H_x + H_t - H_xt\n",
    "\n",
    "    return mutual_information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test the function silvermanmi_univariate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 1.01\n",
    "inputdata= np.array([[1],[2],[3]])\n",
    "layerdata = np.array([[1],[2],[3]])\n",
    "inputdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.816449370561385 4.816449370561385\n",
      "mi:  0.0416007116536366\n"
     ]
    }
   ],
   "source": [
    "mi = silvermanmi_univariate(inputdata, layerdata, alpha)\n",
    "print(\"mi: \",mi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate MI in Ising model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = [\"slices_L1000_D2_T1.5000_pBC\",\n",
    "          \"slices_L1000_D2_T2.3000_pBC\",\n",
    "          \"slices_L1000_D2_T2.2692_pBC\",\n",
    "          \"slices_L1000_D2_T3.5000_pBC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIs = [[],[],[],[]]\n",
    "\n",
    "alpha = 1.01\n",
    "for n in range(4):\n",
    "    data = np.loadtxt(fnames[n], delimiter=None)[:,:100]\n",
    "    # (MCTOT, Linear_size)\n",
    "    print(data.shape)\n",
    "    inputdata = data[:,0].reshape(data.shape[0],1)\n",
    "    for i in range(1,data.shape[1]):\n",
    "        print(i)\n",
    "        layerdata = data[:,i].reshape(data.shape[0],1)\n",
    "        mi = silvermanmi_univariate(inputdata, layerdata, alpha)\n",
    "        MIs[n].append(mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = ['r-','g-','y-','b-']\n",
    "for n in range(4):\n",
    "    plt.plot(list(range(1,100)),MIs[n],markers[n])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
